{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanadinh1203/Data-Analytics-/blob/main/s5332240_LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "f494a246-e199-42b5-f404-6761007354e9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "b9422a81-ee25-48e5-f842-8f25d37174fe",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5741e551-8449-4b91-95a6-4a7b80074da8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d85762-b8a8-4065-9c92-7d0dc56ce418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " F5 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60074 (234.66 KB)\n",
            "Trainable params: 60074 (234.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3,3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name='F5'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "0146f3a0-886f-425b-d2ae-f3b14f1ca9b1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 6s 32ms/step - loss: 1.7836 - accuracy: 0.4880 - val_loss: 0.9612 - val_accuracy: 0.6776\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.7506 - accuracy: 0.7224 - val_loss: 0.6665 - val_accuracy: 0.7428\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6023 - accuracy: 0.7693 - val_loss: 0.5883 - val_accuracy: 0.7771\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5360 - accuracy: 0.7982 - val_loss: 0.5319 - val_accuracy: 0.8068\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5001 - accuracy: 0.8138 - val_loss: 0.5022 - val_accuracy: 0.8146\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.4759 - accuracy: 0.8261 - val_loss: 0.4824 - val_accuracy: 0.8244\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.4480 - accuracy: 0.8375 - val_loss: 0.4807 - val_accuracy: 0.8244\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.4354 - accuracy: 0.8425 - val_loss: 0.4528 - val_accuracy: 0.8331\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4215 - accuracy: 0.8480 - val_loss: 0.4428 - val_accuracy: 0.8374\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8531 - val_loss: 0.4407 - val_accuracy: 0.8425\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3951 - accuracy: 0.8590 - val_loss: 0.4251 - val_accuracy: 0.8494\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3865 - accuracy: 0.8616 - val_loss: 0.4117 - val_accuracy: 0.8553\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8651 - val_loss: 0.4018 - val_accuracy: 0.8586\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3721 - accuracy: 0.8663 - val_loss: 0.3953 - val_accuracy: 0.8583\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.8705 - val_loss: 0.3950 - val_accuracy: 0.8573\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 0.8718 - val_loss: 0.3814 - val_accuracy: 0.8636\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3506 - accuracy: 0.8748 - val_loss: 0.3761 - val_accuracy: 0.8680\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3436 - accuracy: 0.8775 - val_loss: 0.3821 - val_accuracy: 0.8608\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3400 - accuracy: 0.8790 - val_loss: 0.3713 - val_accuracy: 0.8678\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3351 - accuracy: 0.8809 - val_loss: 0.3650 - val_accuracy: 0.8699\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3335 - accuracy: 0.8807 - val_loss: 0.3742 - val_accuracy: 0.8654\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3291 - accuracy: 0.8820 - val_loss: 0.3553 - val_accuracy: 0.8745\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3262 - accuracy: 0.8827 - val_loss: 0.3568 - val_accuracy: 0.8738\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3241 - accuracy: 0.8841 - val_loss: 0.3514 - val_accuracy: 0.8751\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3167 - accuracy: 0.8863 - val_loss: 0.3511 - val_accuracy: 0.8759\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3136 - accuracy: 0.8872 - val_loss: 0.3473 - val_accuracy: 0.8783\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.3079 - accuracy: 0.8903 - val_loss: 0.3486 - val_accuracy: 0.8772\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3041 - accuracy: 0.8918 - val_loss: 0.3439 - val_accuracy: 0.8784\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.8916 - val_loss: 0.3382 - val_accuracy: 0.8813\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3045 - accuracy: 0.8907 - val_loss: 0.3462 - val_accuracy: 0.8756\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2981 - accuracy: 0.8927 - val_loss: 0.3365 - val_accuracy: 0.8807\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2997 - accuracy: 0.8918 - val_loss: 0.3335 - val_accuracy: 0.8793\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2924 - accuracy: 0.8948 - val_loss: 0.3366 - val_accuracy: 0.8798\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2914 - accuracy: 0.8963 - val_loss: 0.3444 - val_accuracy: 0.8723\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2882 - accuracy: 0.8961 - val_loss: 0.3380 - val_accuracy: 0.8784\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2851 - accuracy: 0.8973 - val_loss: 0.3253 - val_accuracy: 0.8845\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2813 - accuracy: 0.8990 - val_loss: 0.3230 - val_accuracy: 0.8866\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2793 - accuracy: 0.8991 - val_loss: 0.3224 - val_accuracy: 0.8839\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2774 - accuracy: 0.8998 - val_loss: 0.3355 - val_accuracy: 0.8798\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2773 - accuracy: 0.8998 - val_loss: 0.3376 - val_accuracy: 0.8805\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2762 - accuracy: 0.9006 - val_loss: 0.3226 - val_accuracy: 0.8862\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2707 - accuracy: 0.9022 - val_loss: 0.3179 - val_accuracy: 0.8865\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2686 - accuracy: 0.9024 - val_loss: 0.3238 - val_accuracy: 0.8850\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2662 - accuracy: 0.9041 - val_loss: 0.3165 - val_accuracy: 0.8874\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2636 - accuracy: 0.9046 - val_loss: 0.3129 - val_accuracy: 0.8898\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2605 - accuracy: 0.9061 - val_loss: 0.3180 - val_accuracy: 0.8835\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2610 - accuracy: 0.9051 - val_loss: 0.3152 - val_accuracy: 0.8856\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.2611 - accuracy: 0.9048 - val_loss: 0.3193 - val_accuracy: 0.8852\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2566 - accuracy: 0.9071 - val_loss: 0.3115 - val_accuracy: 0.8880\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2548 - accuracy: 0.9072 - val_loss: 0.3135 - val_accuracy: 0.8872\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2541 - accuracy: 0.9074 - val_loss: 0.3210 - val_accuracy: 0.8854\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2543 - accuracy: 0.9078 - val_loss: 0.3131 - val_accuracy: 0.8878\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2507 - accuracy: 0.9089 - val_loss: 0.3096 - val_accuracy: 0.8904\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2515 - accuracy: 0.9074 - val_loss: 0.3085 - val_accuracy: 0.8913\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2464 - accuracy: 0.9110 - val_loss: 0.3112 - val_accuracy: 0.8899\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2453 - accuracy: 0.9100 - val_loss: 0.3138 - val_accuracy: 0.8914\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2431 - accuracy: 0.9117 - val_loss: 0.3240 - val_accuracy: 0.8875\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2450 - accuracy: 0.9105 - val_loss: 0.3088 - val_accuracy: 0.8920\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2410 - accuracy: 0.9119 - val_loss: 0.3131 - val_accuracy: 0.8896\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2420 - accuracy: 0.9111 - val_loss: 0.3038 - val_accuracy: 0.8935\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2398 - accuracy: 0.9128 - val_loss: 0.3083 - val_accuracy: 0.8915\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2366 - accuracy: 0.9131 - val_loss: 0.3096 - val_accuracy: 0.8915\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2372 - accuracy: 0.9132 - val_loss: 0.3004 - val_accuracy: 0.8969\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2329 - accuracy: 0.9153 - val_loss: 0.3116 - val_accuracy: 0.8948\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2382 - accuracy: 0.9125 - val_loss: 0.3065 - val_accuracy: 0.8944\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2339 - accuracy: 0.9139 - val_loss: 0.3160 - val_accuracy: 0.8901\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2327 - accuracy: 0.9144 - val_loss: 0.3158 - val_accuracy: 0.8926\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2296 - accuracy: 0.9162 - val_loss: 0.3015 - val_accuracy: 0.8959\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2263 - accuracy: 0.9183 - val_loss: 0.3059 - val_accuracy: 0.8941\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2228 - accuracy: 0.9186 - val_loss: 0.2975 - val_accuracy: 0.8983\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2241 - accuracy: 0.9183 - val_loss: 0.2970 - val_accuracy: 0.8983\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2227 - accuracy: 0.9183 - val_loss: 0.2995 - val_accuracy: 0.8986\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2195 - accuracy: 0.9197 - val_loss: 0.3027 - val_accuracy: 0.8958\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2201 - accuracy: 0.9195 - val_loss: 0.3019 - val_accuracy: 0.8966\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2198 - accuracy: 0.9192 - val_loss: 0.3045 - val_accuracy: 0.8950\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2157 - accuracy: 0.9208 - val_loss: 0.3041 - val_accuracy: 0.8954\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2144 - accuracy: 0.9218 - val_loss: 0.2986 - val_accuracy: 0.8989\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2149 - accuracy: 0.9215 - val_loss: 0.3079 - val_accuracy: 0.8929\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2121 - accuracy: 0.9229 - val_loss: 0.3010 - val_accuracy: 0.8964\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2117 - accuracy: 0.9231 - val_loss: 0.3069 - val_accuracy: 0.8962\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2126 - accuracy: 0.9226 - val_loss: 0.3038 - val_accuracy: 0.8963\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c57632b52d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "df1c4bae-c088-4aae-cc73-ae82a78dcfaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 14ms/step\n",
            "accuracy on train with NN: 0.9229833333333334\n",
            "accuracy on test with NN: 0.8963\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter:\n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "5e64edb6-c9d1-44b6-e400-38982ec59fce",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5da9cbf7d7d8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 50ms/step - loss: 0.4290 - accuracy: 0.8608 - val_loss: 0.3322 - val_accuracy: 0.8837\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.3042 - accuracy: 0.8900 - val_loss: 0.3277 - val_accuracy: 0.8853\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 5s 85ms/step - loss: 0.2827 - accuracy: 0.8987 - val_loss: 0.3164 - val_accuracy: 0.8874\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2790 - accuracy: 0.8988 - val_loss: 0.3137 - val_accuracy: 0.8896\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2702 - accuracy: 0.9020 - val_loss: 0.3074 - val_accuracy: 0.8901\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2665 - accuracy: 0.9034 - val_loss: 0.3026 - val_accuracy: 0.8940\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2630 - accuracy: 0.9045 - val_loss: 0.3085 - val_accuracy: 0.8900\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2607 - accuracy: 0.9057 - val_loss: 0.3025 - val_accuracy: 0.8945\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.2550 - accuracy: 0.9066 - val_loss: 0.3094 - val_accuracy: 0.8902\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2537 - accuracy: 0.9064 - val_loss: 0.2988 - val_accuracy: 0.8952\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2498 - accuracy: 0.9087 - val_loss: 0.2995 - val_accuracy: 0.8930\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2467 - accuracy: 0.9087 - val_loss: 0.3066 - val_accuracy: 0.8905\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2452 - accuracy: 0.9097 - val_loss: 0.3045 - val_accuracy: 0.8903\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2491 - accuracy: 0.9082 - val_loss: 0.3001 - val_accuracy: 0.8936\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2420 - accuracy: 0.9123 - val_loss: 0.3034 - val_accuracy: 0.8931\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2425 - accuracy: 0.9107 - val_loss: 0.3073 - val_accuracy: 0.8905\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2398 - accuracy: 0.9122 - val_loss: 0.2988 - val_accuracy: 0.8952\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 4s 64ms/step - loss: 0.2389 - accuracy: 0.9123 - val_loss: 0.3069 - val_accuracy: 0.8917\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2318 - accuracy: 0.9154 - val_loss: 0.2998 - val_accuracy: 0.8954\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2307 - accuracy: 0.9148 - val_loss: 0.2958 - val_accuracy: 0.8964\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2270 - accuracy: 0.9158 - val_loss: 0.3011 - val_accuracy: 0.8951\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 5s 85ms/step - loss: 0.2268 - accuracy: 0.9166 - val_loss: 0.3000 - val_accuracy: 0.8954\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 6s 108ms/step - loss: 0.2257 - accuracy: 0.9167 - val_loss: 0.2940 - val_accuracy: 0.8952\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 4s 67ms/step - loss: 0.2240 - accuracy: 0.9174 - val_loss: 0.3012 - val_accuracy: 0.8931\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 5s 85ms/step - loss: 0.2239 - accuracy: 0.9188 - val_loss: 0.2965 - val_accuracy: 0.8969\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 4s 69ms/step - loss: 0.2242 - accuracy: 0.9163 - val_loss: 0.3031 - val_accuracy: 0.8937\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 4s 72ms/step - loss: 0.2165 - accuracy: 0.9208 - val_loss: 0.2969 - val_accuracy: 0.8963\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 5s 90ms/step - loss: 0.2201 - accuracy: 0.9206 - val_loss: 0.3007 - val_accuracy: 0.8949\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 5s 80ms/step - loss: 0.2171 - accuracy: 0.9197 - val_loss: 0.2907 - val_accuracy: 0.8991\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 4s 72ms/step - loss: 0.2151 - accuracy: 0.9208 - val_loss: 0.2994 - val_accuracy: 0.8957\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 4s 74ms/step - loss: 0.2123 - accuracy: 0.9216 - val_loss: 0.2936 - val_accuracy: 0.8948\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 4s 69ms/step - loss: 0.2109 - accuracy: 0.9225 - val_loss: 0.2884 - val_accuracy: 0.8997\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 5s 81ms/step - loss: 0.2172 - accuracy: 0.9197 - val_loss: 0.2983 - val_accuracy: 0.8977\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 6s 101ms/step - loss: 0.2087 - accuracy: 0.9244 - val_loss: 0.2957 - val_accuracy: 0.8977\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 5s 84ms/step - loss: 0.2087 - accuracy: 0.9227 - val_loss: 0.2958 - val_accuracy: 0.8980\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 4s 72ms/step - loss: 0.2083 - accuracy: 0.9222 - val_loss: 0.2983 - val_accuracy: 0.8974\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 6s 97ms/step - loss: 0.2068 - accuracy: 0.9221 - val_loss: 0.2983 - val_accuracy: 0.8986\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 4s 72ms/step - loss: 0.2010 - accuracy: 0.9254 - val_loss: 0.2948 - val_accuracy: 0.8997\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 5s 82ms/step - loss: 0.2004 - accuracy: 0.9262 - val_loss: 0.2990 - val_accuracy: 0.8979\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 4s 64ms/step - loss: 0.2030 - accuracy: 0.9259 - val_loss: 0.3093 - val_accuracy: 0.8949\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 4s 75ms/step - loss: 0.2005 - accuracy: 0.9259 - val_loss: 0.2997 - val_accuracy: 0.8997\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 4s 71ms/step - loss: 0.1994 - accuracy: 0.9265 - val_loss: 0.3028 - val_accuracy: 0.8975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c56cd62b850>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "5600e49a-3440-4df0-9336-16f728c2ea78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 5ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "accuracy on train with NN: 0.9312666666666667\n",
            "accuracy on test with NN: 0.8975\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}